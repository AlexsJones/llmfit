[
  {
    "name": "nomic-ai/nomic-embed-text-v1.5",
    "provider": "Nomic",
    "parameter_count": "137M",
    "parameters_raw": 137000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "F16",
    "context_length": 8192,
    "use_case": "Text embeddings for RAG",
    "pipeline_tag": "feature-extraction",
    "architecture": "nomic_bert",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "BAAI/bge-large-en-v1.5",
    "provider": "BAAI",
    "parameter_count": "335M",
    "parameters_raw": 335142400,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "Q4_K_M",
    "context_length": 512,
    "use_case": "Text embeddings for RAG",
    "pipeline_tag": "feature-extraction",
    "architecture": "bert",
    "hf_downloads": 5065096,
    "hf_likes": 627
  },
  {
    "name": "Qwen/Qwen3-0.6B",
    "provider": "Alibaba",
    "parameter_count": "752M",
    "parameters_raw": 751632384,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 10230703,
    "hf_likes": 1086
  },
  {
    "name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "provider": "Community",
    "parameter_count": "1.1B",
    "parameters_raw": 1100048384,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.6,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1790563,
    "hf_likes": 1527
  },
  {
    "name": "meta-llama/Llama-3.2-1B",
    "provider": "Meta",
    "parameter_count": "1.2B",
    "parameters_raw": 1235814400,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1713795,
    "hf_likes": 2295
  },
  {
    "name": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "1.5B",
    "parameters_raw": 1543714304,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1486132,
    "hf_likes": 106
  },
  {
    "name": "stabilityai/stablelm-2-1_6b-chat",
    "provider": "Stability AI",
    "parameter_count": "1.6B",
    "parameters_raw": 1644515328,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.8,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "stablelm",
    "hf_downloads": 449,
    "hf_likes": 34
  },
  {
    "name": "google/gemma-2-2b-it",
    "provider": "Google",
    "parameter_count": "2.6B",
    "parameters_raw": 2614341888,
    "min_ram_gb": 1.5,
    "recommended_ram_gb": 2.4,
    "min_vram_gb": 1.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 356548,
    "hf_likes": 1286
  },
  {
    "name": "meta-llama/Llama-3.2-3B",
    "provider": "Meta",
    "parameter_count": "3.2B",
    "parameters_raw": 3212749824,
    "min_ram_gb": 1.8,
    "recommended_ram_gb": 3.0,
    "min_vram_gb": 1.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 797220,
    "hf_likes": 697
  },
  {
    "name": "Qwen/Qwen2.5-VL-3B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "3.8B",
    "parameters_raw": 3754622976,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.5,
    "min_vram_gb": 1.9,
    "quantization": "Q4_K_M",
    "context_length": 128000,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "image-text-to-text",
    "architecture": "qwen2_5_vl",
    "hf_downloads": 21447348,
    "hf_likes": 608
  },
  {
    "name": "microsoft/phi-3-mini-4k-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-3.5-mini-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Lightweight, long context",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-4-mini-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3836021760,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 220158,
    "hf_likes": 685
  },
  {
    "name": "Qwen/Qwen3-4B",
    "provider": "Alibaba",
    "parameter_count": "4.0B",
    "parameters_raw": 4022468096,
    "min_ram_gb": 2.2,
    "recommended_ram_gb": 3.7,
    "min_vram_gb": 2.1,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 4999230,
    "hf_likes": 553
  },
  {
    "name": "01-ai/Yi-6B-Chat",
    "provider": "01.ai",
    "parameter_count": "6.1B",
    "parameters_raw": 6061035520,
    "min_ram_gb": 3.4,
    "recommended_ram_gb": 5.6,
    "min_vram_gb": 3.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 13210,
    "hf_likes": 70
  },
  {
    "name": "lmsys/vicuna-7b-v1.5",
    "provider": "LMSYS",
    "parameter_count": "7.0B",
    "parameters_raw": 6738415616,
    "min_ram_gb": 3.8,
    "recommended_ram_gb": 6.3,
    "min_vram_gb": 3.4,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/CodeLlama-7b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "6.7B",
    "parameters_raw": 6738546688,
    "min_ram_gb": 3.8,
    "recommended_ram_gb": 6.3,
    "min_vram_gb": 3.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 3947,
    "hf_likes": 59
  },
  {
    "name": "openchat/openchat-3.5-0106",
    "provider": "OpenChat",
    "parameter_count": "7.0B",
    "parameters_raw": 7000000000,
    "min_ram_gb": 3.9,
    "recommended_ram_gb": 6.5,
    "min_vram_gb": 3.6,
    "quantization": "Q4_K_M",
    "context_length": 8192,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Orca-2-7b",
    "provider": "Microsoft",
    "parameter_count": "7.0B",
    "parameters_raw": 7016400896,
    "min_ram_gb": 3.9,
    "recommended_ram_gb": 6.5,
    "min_vram_gb": 3.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Reasoning, step-by-step solutions",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "bigcode/starcoder2-7b",
    "provider": "BigCode",
    "parameter_count": "7.2B",
    "parameters_raw": 7173923840,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder2",
    "hf_downloads": 17185,
    "hf_likes": 209
  },
  {
    "name": "tiiuae/falcon-7b-instruct",
    "provider": "TII",
    "parameter_count": "7.2B",
    "parameters_raw": 7217189760,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 42702,
    "hf_likes": 1030
  },
  {
    "name": "HuggingFaceH4/zephyr-7b-beta",
    "provider": "HuggingFace",
    "parameter_count": "7.2B",
    "parameters_raw": 7241732096,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 76482,
    "hf_likes": 1832
  },
  {
    "name": "mistralai/Mistral-7B-Instruct-v0.3",
    "provider": "Mistral AI",
    "parameter_count": "7.2B",
    "parameters_raw": 7248023552,
    "min_ram_gb": 4.1,
    "recommended_ram_gb": 6.8,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mistral",
    "hf_downloads": 1214674,
    "hf_likes": 2425
  },
  {
    "name": "tiiuae/Falcon3-7B-Instruct",
    "provider": "TII",
    "parameter_count": "7.5B",
    "parameters_raw": 7455550464,
    "min_ram_gb": 4.2,
    "recommended_ram_gb": 6.9,
    "min_vram_gb": 3.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 13635,
    "hf_likes": 76
  },
  {
    "name": "Qwen/Qwen2.5-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 13965574,
    "hf_likes": 1074
  },
  {
    "name": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1423701,
    "hf_likes": 649
  },
  {
    "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "provider": "DeepSeek",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 729695,
    "hf_likes": 787
  },
  {
    "name": "meta-llama/Llama-3.1-8B",
    "provider": "Meta",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1215441,
    "hf_likes": 2067
  },
  {
    "name": "meta-llama/Llama-3.1-8B-Instruct",
    "provider": "Meta",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 5838710,
    "hf_likes": 5469
  },
  {
    "name": "mistralai/Ministral-8B-Instruct-2410",
    "provider": "Mistral AI",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-8B",
    "provider": "Alibaba",
    "parameter_count": "8.2B",
    "parameters_raw": 8190735360,
    "min_ram_gb": 4.6,
    "recommended_ram_gb": 7.6,
    "min_vram_gb": 4.2,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 4824362,
    "hf_likes": 940
  },
  {
    "name": "Qwen/Qwen2.5-VL-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "8.3B",
    "parameters_raw": 8290000000,
    "min_ram_gb": 4.6,
    "recommended_ram_gb": 7.7,
    "min_vram_gb": 4.2,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "image-text-to-text",
    "architecture": "qwen2_vl",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-2-9b-it",
    "provider": "Google",
    "parameter_count": "9.2B",
    "parameters_raw": 9241705984,
    "min_ram_gb": 5.2,
    "recommended_ram_gb": 8.6,
    "min_vram_gb": 4.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 151158,
    "hf_likes": 768
  },
  {
    "name": "THUDM/glm-4-9b-chat",
    "provider": "thudm",
    "parameter_count": "9.4B",
    "parameters_raw": 9399951392,
    "min_ram_gb": 5.3,
    "recommended_ram_gb": 8.8,
    "min_vram_gb": 4.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "chatglm",
    "hf_downloads": 88272,
    "hf_likes": 699
  },
  {
    "name": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "provider": "Meta",
    "parameter_count": "10.7B",
    "parameters_raw": 10670220835,
    "min_ram_gb": 6.0,
    "recommended_ram_gb": 9.9,
    "min_vram_gb": 5.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "image-text-to-text",
    "architecture": "mllama",
    "hf_downloads": 166969,
    "hf_likes": 1563
  },
  {
    "name": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "provider": "Upstage",
    "parameter_count": "10.7B",
    "parameters_raw": 10700000000,
    "min_ram_gb": 6.0,
    "recommended_ram_gb": 10.0,
    "min_vram_gb": 5.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "High-performance instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-3-12b-it",
    "provider": "Google",
    "parameter_count": "12B",
    "parameters_raw": 12000000000,
    "min_ram_gb": 6.7,
    "recommended_ram_gb": 11.2,
    "min_vram_gb": 6.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "text-generation",
    "architecture": "gemma3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mistral-Nemo-Instruct-2407",
    "provider": "Mistral AI",
    "parameter_count": "12.2B",
    "parameters_raw": 12247076864,
    "min_ram_gb": 6.8,
    "recommended_ram_gb": 11.4,
    "min_vram_gb": 6.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Orca-2-13b",
    "provider": "Microsoft",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Reasoning, step-by-step solutions",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "lmsys/vicuna-13b-v1.5",
    "provider": "LMSYS",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "WizardLMTeam/WizardLM-13B-V1.2",
    "provider": "WizardLM",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/CodeLlama-13b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "13.0B",
    "parameters_raw": 13016028160,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 4219,
    "hf_likes": 27
  },
  {
    "name": "microsoft/phi-4",
    "provider": "Microsoft",
    "parameter_count": "14B",
    "parameters_raw": 14000000000,
    "min_ram_gb": 7.8,
    "recommended_ram_gb": 13.0,
    "min_vram_gb": 7.2,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Reasoning, STEM, code generation",
    "pipeline_tag": "text-generation",
    "architecture": "phi",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-3-medium-14b-instruct",
    "provider": "Microsoft",
    "parameter_count": "14B",
    "parameters_raw": 14000000000,
    "min_ram_gb": 7.8,
    "recommended_ram_gb": 13.0,
    "min_vram_gb": 7.2,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Balanced performance and size",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-14B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770000000,
    "min_ram_gb": 8.2,
    "recommended_ram_gb": 13.7,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-14B",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770000000,
    "min_ram_gb": 8.2,
    "recommended_ram_gb": 13.7,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-Coder-14B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770033664,
    "min_ram_gb": 8.3,
    "recommended_ram_gb": 13.8,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 407362,
    "hf_likes": 140
  },
  {
    "name": "WizardLMTeam/WizardCoder-15B-V1.0",
    "provider": "WizardLM",
    "parameter_count": "15.5B",
    "parameters_raw": 15515334656,
    "min_ram_gb": 8.7,
    "recommended_ram_gb": 14.5,
    "min_vram_gb": 7.9,
    "quantization": "Q4_K_M",
    "context_length": 8192,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "bigcode/starcoder2-15b",
    "provider": "BigCode",
    "parameter_count": "15.7B",
    "parameters_raw": 15700000000,
    "min_ram_gb": 8.8,
    "recommended_ram_gb": 14.6,
    "min_vram_gb": 8.0,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "provider": "DeepSeek",
    "parameter_count": "16B",
    "parameters_raw": 15700000000,
    "min_ram_gb": 8.8,
    "recommended_ram_gb": 14.6,
    "min_vram_gb": 8.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v2",
    "is_moe": true,
    "num_experts": 64,
    "active_experts": 6,
    "active_parameters": 2400000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "inclusionAI/Ling-lite",
    "provider": "inclusionai",
    "parameter_count": "16.8B",
    "parameters_raw": 16801974272,
    "min_ram_gb": 9.4,
    "recommended_ram_gb": 15.6,
    "min_vram_gb": 8.6,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "bailing_moe",
    "hf_downloads": 180,
    "hf_likes": 78
  },
  {
    "name": "openai/gpt-oss-20b",
    "provider": "openai",
    "parameter_count": "21.5B",
    "parameters_raw": 21511953984,
    "min_ram_gb": 12.0,
    "recommended_ram_gb": 20.0,
    "min_vram_gb": 11.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gpt_oss",
    "hf_downloads": 5479694,
    "hf_likes": 4380,
    "is_moe": true,
    "num_experts": 32,
    "active_experts": 4,
    "active_parameters": 3630142231
  },
  {
    "name": "mistralai/Mistral-Small-24B-Instruct-2501",
    "provider": "Mistral AI",
    "parameter_count": "24B",
    "parameters_raw": 24000000000,
    "min_ram_gb": 13.4,
    "recommended_ram_gb": 22.4,
    "min_vram_gb": 12.3,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Devstral/Devstral-Small-2-24B-Instruct-2512",
    "provider": "Devstral",
    "parameter_count": "24B",
    "parameters_raw": 24000000000,
    "min_ram_gb": 13.4,
    "recommended_ram_gb": 22.4,
    "min_vram_gb": 12.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-2-27b-it",
    "provider": "Google",
    "parameter_count": "27.2B",
    "parameters_raw": 27227128320,
    "min_ram_gb": 15.2,
    "recommended_ram_gb": 25.4,
    "min_vram_gb": 13.9,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 394781,
    "hf_likes": 559
  },
  {
    "name": "ZhipuAI/GLM-4.7-Flash-0414",
    "provider": "Zhipu AI",
    "parameter_count": "30B",
    "parameters_raw": 30000000000,
    "min_ram_gb": 16.8,
    "recommended_ram_gb": 28.0,
    "min_vram_gb": 15.4,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Fast inference, general purpose",
    "pipeline_tag": "text-generation",
    "architecture": "glm4",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-30B-A3B",
    "provider": "Alibaba",
    "parameter_count": "30.5B",
    "parameters_raw": 30532122624,
    "min_ram_gb": 17.1,
    "recommended_ram_gb": 28.4,
    "min_vram_gb": 15.6,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "hf_downloads": 1108640,
    "hf_likes": 855,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 3300000000
  },
  {
    "name": "allenai/OLMo-2-0325-32B-Instruct",
    "provider": "allenai",
    "parameter_count": "32.2B",
    "parameters_raw": 32234279936,
    "min_ram_gb": 18.0,
    "recommended_ram_gb": 30.0,
    "min_vram_gb": 16.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "olmo2",
    "hf_downloads": 1367,
    "hf_likes": 148
  },
  {
    "name": "Qwen/Qwen2.5-32B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "32.5B",
    "parameters_raw": 32510000000,
    "min_ram_gb": 18.2,
    "recommended_ram_gb": 30.3,
    "min_vram_gb": 16.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-32B",
    "provider": "Alibaba",
    "parameter_count": "32.8B",
    "parameters_raw": 32762123264,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 40960,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 1601172,
    "hf_likes": 657
  },
  {
    "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "32.8B",
    "parameters_raw": 32763876352,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 731078,
    "hf_likes": 1995
  },
  {
    "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "provider": "DeepSeek",
    "parameter_count": "32.8B",
    "parameters_raw": 32763876352,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1131453,
    "hf_likes": 1517
  },
  {
    "name": "meta-llama/CodeLlama-34b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "33.7B",
    "parameters_raw": 33743970304,
    "min_ram_gb": 18.9,
    "recommended_ram_gb": 31.4,
    "min_vram_gb": 17.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1043,
    "hf_likes": 18
  },
  {
    "name": "01-ai/Yi-34B-Chat",
    "provider": "01.ai",
    "parameter_count": "34.4B",
    "parameters_raw": 34388917248,
    "min_ram_gb": 19.2,
    "recommended_ram_gb": 32.0,
    "min_vram_gb": 17.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 13398,
    "hf_likes": 357
  },
  {
    "name": "CohereForAI/c4ai-command-r-v01",
    "provider": "Cohere",
    "parameter_count": "35B",
    "parameters_raw": 35000000000,
    "min_ram_gb": 19.5,
    "recommended_ram_gb": 32.6,
    "min_vram_gb": 17.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "RAG, tool use, agents",
    "pipeline_tag": "text-generation",
    "architecture": "cohere",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "tiiuae/falcon-40b-instruct",
    "provider": "TII",
    "parameter_count": "40.0B",
    "parameters_raw": 40000000000,
    "min_ram_gb": 22.4,
    "recommended_ram_gb": 37.3,
    "min_vram_gb": 20.5,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "provider": "Mistral AI",
    "parameter_count": "46.7B",
    "parameters_raw": 46702792704,
    "min_ram_gb": 26.1,
    "recommended_ram_gb": 43.5,
    "min_vram_gb": 23.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mixtral",
    "hf_downloads": 582025,
    "hf_likes": 4637,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 12900000000
  },
  {
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "provider": "NousResearch",
    "parameter_count": "46.7B",
    "parameters_raw": 46702809088,
    "min_ram_gb": 26.1,
    "recommended_ram_gb": 43.5,
    "min_vram_gb": 23.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "mixtral",
    "hf_downloads": 8149,
    "hf_likes": 453,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 12900000000
  },
  {
    "name": "meta-llama/Llama-3.1-70B-Instruct",
    "provider": "Meta",
    "parameter_count": "70.6B",
    "parameters_raw": 70553706496,
    "min_ram_gb": 39.4,
    "recommended_ram_gb": 65.7,
    "min_vram_gb": 36.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 712000,
    "hf_likes": 891
  },
  {
    "name": "meta-llama/Llama-3.3-70B-Instruct",
    "provider": "Meta",
    "parameter_count": "70.6B",
    "parameters_raw": 70553706496,
    "min_ram_gb": 39.4,
    "recommended_ram_gb": 65.7,
    "min_vram_gb": 36.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-72B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "72.7B",
    "parameters_raw": 72706203648,
    "min_ram_gb": 40.6,
    "recommended_ram_gb": 67.7,
    "min_vram_gb": 37.2,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 345423,
    "hf_likes": 910
  },
  {
    "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "80B",
    "parameters_raw": 80000000000,
    "min_ram_gb": 44.7,
    "recommended_ram_gb": 74.5,
    "min_vram_gb": 41.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Efficient MoE, general purpose",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 8000000000
  },
  {
    "name": "openai/gpt-oss-120b",
    "provider": "openai",
    "parameter_count": "120.4B",
    "parameters_raw": 120412337472,
    "min_ram_gb": 67.3,
    "recommended_ram_gb": 112.1,
    "min_vram_gb": 61.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gpt_oss",
    "hf_downloads": 3483599,
    "hf_likes": 4505,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 4,
    "active_parameters": 9595358141
  },
  {
    "name": "mistralai/Mistral-Large-Instruct-2407",
    "provider": "Mistral AI",
    "parameter_count": "122.6B",
    "parameters_raw": 122610069504,
    "min_ram_gb": 68.5,
    "recommended_ram_gb": 114.2,
    "min_vram_gb": 62.8,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mistral",
    "hf_downloads": 6003,
    "hf_likes": 855
  },
  {
    "name": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "provider": "Mistral AI",
    "parameter_count": "140.6B",
    "parameters_raw": 140630071296,
    "min_ram_gb": 78.6,
    "recommended_ram_gb": 131.0,
    "min_vram_gb": 72.0,
    "quantization": "Q4_K_M",
    "context_length": 65536,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mixtral",
    "hf_downloads": 10997,
    "hf_likes": 746,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 39100000000
  },
  {
    "name": "rednote-hilab/dots.llm1.inst",
    "provider": "rednote-hilab",
    "parameter_count": "142.8B",
    "parameters_raw": 142774381696,
    "min_ram_gb": 79.8,
    "recommended_ram_gb": 133.0,
    "min_vram_gb": 73.1,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "dots1",
    "hf_downloads": 4616,
    "hf_likes": 175
  },
  {
    "name": "bigscience/bloom",
    "provider": "bigscience",
    "parameter_count": "176.2B",
    "parameters_raw": 176247271424,
    "min_ram_gb": 98.5,
    "recommended_ram_gb": 164.1,
    "min_vram_gb": 90.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "bloom",
    "hf_downloads": 3222,
    "hf_likes": 4985
  },
  {
    "name": "tiiuae/falcon-180B-chat",
    "provider": "TII",
    "parameter_count": "179.5B",
    "parameters_raw": 179522565120,
    "min_ram_gb": 100.3,
    "recommended_ram_gb": 167.2,
    "min_vram_gb": 92.0,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 74,
    "hf_likes": 545
  },
  {
    "name": "MiniMax/MiniMax-M2.1",
    "provider": "MiniMax",
    "parameter_count": "229B",
    "parameters_raw": 229000000000,
    "min_ram_gb": 128.0,
    "recommended_ram_gb": 213.3,
    "min_vram_gb": 117.4,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "State-of-the-art, MoE architecture",
    "pipeline_tag": "text-generation",
    "architecture": "minimax",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 18000000000
  },
  {
    "name": "baidu/ERNIE-4.5-300B-A47B-Paddle",
    "provider": "baidu",
    "parameter_count": "300.5B",
    "parameters_raw": 300474051776,
    "min_ram_gb": 167.9,
    "recommended_ram_gb": 279.8,
    "min_vram_gb": 153.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "ernie4_5_moe",
    "hf_downloads": 34,
    "hf_likes": 12
  },
  {
    "name": "ZhipuAI/GLM-4.7-0414",
    "provider": "Zhipu AI",
    "parameter_count": "353B",
    "parameters_raw": 353000000000,
    "min_ram_gb": 197.3,
    "recommended_ram_gb": 328.8,
    "min_vram_gb": 180.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Large-scale multilingual reasoning",
    "pipeline_tag": "text-generation",
    "architecture": "glm4",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 32000000000
  },
  {
    "name": "meta-llama/Llama-3.1-405B-Instruct",
    "provider": "Meta",
    "parameter_count": "405.9B",
    "parameters_raw": 405853388800,
    "min_ram_gb": 226.8,
    "recommended_ram_gb": 378.0,
    "min_vram_gb": 207.9,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 149248,
    "hf_likes": 592
  },
  {
    "name": "deepseek-ai/DeepSeek-R1",
    "provider": "DeepSeek",
    "parameter_count": "684.5B",
    "parameters_raw": 684531386000,
    "min_ram_gb": 382.5,
    "recommended_ram_gb": 637.5,
    "min_vram_gb": 350.6,
    "quantization": "Q4_K_M",
    "context_length": 163840,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v3",
    "hf_downloads": 575991,
    "hf_likes": 13013,
    "is_moe": true,
    "num_experts": 256,
    "active_experts": 8,
    "active_parameters": 37000000000
  },
  {
    "name": "deepseek-ai/DeepSeek-V3.1",
    "provider": "DeepSeek",
    "parameter_count": "684.5B",
    "parameters_raw": 684531386000,
    "min_ram_gb": 382.5,
    "recommended_ram_gb": 637.5,
    "min_vram_gb": 350.6,
    "quantization": "Q4_K_M",
    "context_length": 163840,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v3",
    "hf_downloads": 123794,
    "hf_likes": 816,
    "is_moe": true,
    "num_experts": 256,
    "active_experts": 8,
    "active_parameters": 54548594820
  },
  {
    "name": "deepseek-ai/DeepSeek-V3",
    "provider": "DeepSeek",
    "parameter_count": "685B",
    "parameters_raw": 685000000000,
    "min_ram_gb": 382.8,
    "recommended_ram_gb": 638.0,
    "min_vram_gb": 351.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "State-of-the-art, MoE architecture",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v3",
    "is_moe": true,
    "num_experts": 256,
    "active_experts": 8,
    "active_parameters": 37000000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "moonshotai/Kimi-K2.5-Instruct",
    "provider": "Moonshot",
    "parameter_count": "1000B",
    "parameters_raw": 1000000000000,
    "min_ram_gb": 558.8,
    "recommended_ram_gb": 931.3,
    "min_vram_gb": 512.2,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Large MoE, reasoning",
    "pipeline_tag": "text-generation",
    "architecture": "kimi",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 384,
    "active_experts": 8,
    "active_parameters": 32000000000
  },
  {
    "name": "moonshotai/Kimi-K2-Thinking",
    "provider": "Moonshot",
    "parameter_count": "1000B",
    "parameters_raw": 1000000000000,
    "min_ram_gb": 558.8,
    "recommended_ram_gb": 931.3,
    "min_vram_gb": 512.2,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Reasoning with chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "kimi",
    "hf_downloads": 0,
    "hf_likes": 0,
    "is_moe": true,
    "num_experts": 384,
    "active_experts": 8,
    "active_parameters": 32000000000
  }
]