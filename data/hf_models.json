[
  {
    "name": "nomic-ai/nomic-embed-text-v1.5",
    "provider": "Nomic",
    "parameter_count": "137M",
    "parameters_raw": 137000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.5,
    "quantization": "F16",
    "context_length": 8192,
    "use_case": "Text embeddings for RAG",
    "pipeline_tag": "feature-extraction",
    "architecture": "nomic_bert",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-0.6B",
    "provider": "Alibaba",
    "parameter_count": "0.6B",
    "parameters_raw": 600000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 1.5,
    "min_vram_gb": 0.4,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "provider": "Community",
    "parameter_count": "1.1B",
    "parameters_raw": 1100048384,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.6,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1817970,
    "hf_likes": 1528
  },
  {
    "name": "meta-llama/Llama-3.2-1B",
    "provider": "Meta",
    "parameter_count": "1.2B",
    "parameters_raw": 1235814400,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1424122,
    "hf_likes": 2296
  },
  {
    "name": "Qwen/Qwen2.5-Coder-1.5B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "1.5B",
    "parameters_raw": 1543714304,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1545260,
    "hf_likes": 106
  },
  {
    "name": "stabilityai/stablelm-2-1_6b-chat",
    "provider": "Stability AI",
    "parameter_count": "1.6B",
    "parameters_raw": 1644515328,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.8,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "stablelm",
    "hf_downloads": 489,
    "hf_likes": 34
  },
  {
    "name": "Qwen/Qwen3-1.7B",
    "provider": "Alibaba",
    "parameter_count": "1.7B",
    "parameters_raw": 1700000000,
    "min_ram_gb": 1.0,
    "recommended_ram_gb": 2.0,
    "min_vram_gb": 0.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-VL-2B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "2.5B",
    "parameters_raw": 2510000000,
    "min_ram_gb": 1.5,
    "recommended_ram_gb": 2.5,
    "min_vram_gb": 1.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "image-text-to-text",
    "architecture": "qwen3_vl",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-2-2b-it",
    "provider": "Google",
    "parameter_count": "2.6B",
    "parameters_raw": 2614341376,
    "min_ram_gb": 1.5,
    "recommended_ram_gb": 2.4,
    "min_vram_gb": 1.3,
    "quantization": "Q4_K_M",
    "context_length": 8192,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/Llama-3.2-3B",
    "provider": "Meta",
    "parameter_count": "3.2B",
    "parameters_raw": 3212749824,
    "min_ram_gb": 1.8,
    "recommended_ram_gb": 3.0,
    "min_vram_gb": 1.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1224954,
    "hf_likes": 698
  },
  {
    "name": "Qwen/Qwen2.5-VL-3B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "3.8B",
    "parameters_raw": 3754622976,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.5,
    "min_vram_gb": 1.9,
    "quantization": "Q4_K_M",
    "context_length": 128000,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "image-text-to-text",
    "architecture": "qwen2_5_vl",
    "hf_downloads": 19875282,
    "hf_likes": 613
  },
  {
    "name": "microsoft/phi-3-mini-4k-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Lightweight, edge deployment",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-3.5-mini-instruct",
    "provider": "Microsoft",
    "parameter_count": "3.8B",
    "parameters_raw": 3821000000,
    "min_ram_gb": 2.1,
    "recommended_ram_gb": 3.6,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Lightweight, long context",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-4B",
    "provider": "Alibaba",
    "parameter_count": "4.0B",
    "parameters_raw": 4000000000,
    "min_ram_gb": 2.2,
    "recommended_ram_gb": 3.7,
    "min_vram_gb": 2.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "01-ai/Yi-6B-Chat",
    "provider": "01.ai",
    "parameter_count": "6.1B",
    "parameters_raw": 6061035520,
    "min_ram_gb": 3.4,
    "recommended_ram_gb": 5.6,
    "min_vram_gb": 3.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 12688,
    "hf_likes": 70
  },
  {
    "name": "lmsys/vicuna-7b-v1.5",
    "provider": "LMSYS",
    "parameter_count": "7.0B",
    "parameters_raw": 6738415616,
    "min_ram_gb": 3.8,
    "recommended_ram_gb": 6.3,
    "min_vram_gb": 3.4,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/CodeLlama-7b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "6.7B",
    "parameters_raw": 6738546688,
    "min_ram_gb": 3.8,
    "recommended_ram_gb": 6.3,
    "min_vram_gb": 3.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 4689,
    "hf_likes": 59
  },
  {
    "name": "openchat/openchat-3.5-0106",
    "provider": "OpenChat",
    "parameter_count": "7.0B",
    "parameters_raw": 7000000000,
    "min_ram_gb": 3.9,
    "recommended_ram_gb": 6.5,
    "min_vram_gb": 3.6,
    "quantization": "Q4_K_M",
    "context_length": 8192,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Orca-2-7b",
    "provider": "Microsoft",
    "parameter_count": "7.0B",
    "parameters_raw": 7016400896,
    "min_ram_gb": 3.9,
    "recommended_ram_gb": 6.5,
    "min_vram_gb": 3.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Reasoning, step-by-step solutions",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "bigcode/starcoder2-7b",
    "provider": "BigCode",
    "parameter_count": "7.2B",
    "parameters_raw": 7173923840,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder2",
    "hf_downloads": 17466,
    "hf_likes": 208
  },
  {
    "name": "tiiuae/falcon-7b-instruct",
    "provider": "TII",
    "parameter_count": "7.2B",
    "parameters_raw": 7217189760,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 43322,
    "hf_likes": 1030
  },
  {
    "name": "HuggingFaceH4/zephyr-7b-beta",
    "provider": "HuggingFace",
    "parameter_count": "7.2B",
    "parameters_raw": 7241732096,
    "min_ram_gb": 4.0,
    "recommended_ram_gb": 6.7,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 79979,
    "hf_likes": 1832
  },
  {
    "name": "mistralai/Mistral-7B-Instruct-v0.3",
    "provider": "Mistral AI",
    "parameter_count": "7.2B",
    "parameters_raw": 7248023552,
    "min_ram_gb": 4.1,
    "recommended_ram_gb": 6.8,
    "min_vram_gb": 3.7,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mistral",
    "hf_downloads": 1201883,
    "hf_likes": 2428
  },
  {
    "name": "tiiuae/Falcon3-7B-Instruct",
    "provider": "TII",
    "parameter_count": "7.5B",
    "parameters_raw": 7455550464,
    "min_ram_gb": 4.2,
    "recommended_ram_gb": 6.9,
    "min_vram_gb": 3.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 13333,
    "hf_likes": 76
  },
  {
    "name": "Qwen/Qwen2.5-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 15327136,
    "hf_likes": 1084
  },
  {
    "name": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 1399115,
    "hf_likes": 651
  },
  {
    "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    "provider": "DeepSeek",
    "parameter_count": "7.6B",
    "parameters_raw": 7615616512,
    "min_ram_gb": 4.3,
    "recommended_ram_gb": 7.1,
    "min_vram_gb": 3.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 742420,
    "hf_likes": 788
  },
  {
    "name": "Qwen/Qwen3-8B",
    "provider": "Alibaba",
    "parameter_count": "8.0B",
    "parameters_raw": 8000000000,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.4,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Ministral-8B-Instruct-2410",
    "provider": "Mistral AI",
    "parameter_count": "8.0B",
    "parameters_raw": 8030261248,
    "min_ram_gb": 4.5,
    "recommended_ram_gb": 7.5,
    "min_vram_gb": 4.1,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-VL-7B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "8.3B",
    "parameters_raw": 8290000000,
    "min_ram_gb": 4.6,
    "recommended_ram_gb": 7.7,
    "min_vram_gb": 4.2,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "image-text-to-text",
    "architecture": "qwen2_vl",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-VL-8B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "8.8B",
    "parameters_raw": 8767123696,
    "min_ram_gb": 4.9,
    "recommended_ram_gb": 8.2,
    "min_vram_gb": 4.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "image-text-to-text",
    "architecture": "qwen3_vl",
    "hf_downloads": 3731926,
    "hf_likes": 763
  },
  {
    "name": "google/gemma-2-9b-it",
    "provider": "Google",
    "parameter_count": "9.2B",
    "parameters_raw": 9241705984,
    "min_ram_gb": 5.2,
    "recommended_ram_gb": 8.6,
    "min_vram_gb": 4.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 139170,
    "hf_likes": 768
  },
  {
    "name": "THUDM/glm-4-9b-chat",
    "provider": "thudm",
    "parameter_count": "9.4B",
    "parameters_raw": 9399951392,
    "min_ram_gb": 5.3,
    "recommended_ram_gb": 8.8,
    "min_vram_gb": 4.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "chatglm",
    "hf_downloads": 90003,
    "hf_likes": 699
  },
  {
    "name": "meta-llama/Llama-3.2-11B-Vision-Instruct",
    "provider": "Meta",
    "parameter_count": "11.0B",
    "parameters_raw": 10665463808,
    "min_ram_gb": 6.0,
    "recommended_ram_gb": 9.9,
    "min_vram_gb": 5.5,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "image-text-to-text",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "upstage/SOLAR-10.7B-Instruct-v1.0",
    "provider": "Upstage",
    "parameter_count": "10.7B",
    "parameters_raw": 10700000000,
    "min_ram_gb": 6.0,
    "recommended_ram_gb": 10.0,
    "min_vram_gb": 5.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "High-performance instruction following",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-3-12b-it",
    "provider": "Google",
    "parameter_count": "12B",
    "parameters_raw": 12000000000,
    "min_ram_gb": 6.7,
    "recommended_ram_gb": 11.2,
    "min_vram_gb": 6.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Multimodal, vision and text",
    "pipeline_tag": "text-generation",
    "architecture": "gemma3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mistral-Nemo-Instruct-2407",
    "provider": "Mistral AI",
    "parameter_count": "12.2B",
    "parameters_raw": 12247076864,
    "min_ram_gb": 6.8,
    "recommended_ram_gb": 11.4,
    "min_vram_gb": 6.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Orca-2-13b",
    "provider": "Microsoft",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Reasoning, step-by-step solutions",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "lmsys/vicuna-13b-v1.5",
    "provider": "LMSYS",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "WizardLMTeam/WizardLM-13B-V1.2",
    "provider": "WizardLM",
    "parameter_count": "13.0B",
    "parameters_raw": 13015864320,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/CodeLlama-13b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "13.0B",
    "parameters_raw": 13016028160,
    "min_ram_gb": 7.3,
    "recommended_ram_gb": 12.1,
    "min_vram_gb": 6.7,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 4806,
    "hf_likes": 27
  },
  {
    "name": "microsoft/phi-4",
    "provider": "Microsoft",
    "parameter_count": "14B",
    "parameters_raw": 14000000000,
    "min_ram_gb": 7.8,
    "recommended_ram_gb": 13.0,
    "min_vram_gb": 7.2,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Reasoning, STEM, code generation",
    "pipeline_tag": "text-generation",
    "architecture": "phi",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "microsoft/Phi-3-medium-14b-instruct",
    "provider": "Microsoft",
    "parameter_count": "14B",
    "parameters_raw": 14000000000,
    "min_ram_gb": 7.8,
    "recommended_ram_gb": 13.0,
    "min_vram_gb": 7.2,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Balanced performance and size",
    "pipeline_tag": "text-generation",
    "architecture": "phi3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-14B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770000000,
    "min_ram_gb": 8.2,
    "recommended_ram_gb": 13.7,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-14B",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770000000,
    "min_ram_gb": 8.2,
    "recommended_ram_gb": 13.7,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-Coder-14B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "14.8B",
    "parameters_raw": 14770033664,
    "min_ram_gb": 8.3,
    "recommended_ram_gb": 13.8,
    "min_vram_gb": 7.6,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 423651,
    "hf_likes": 140
  },
  {
    "name": "WizardLMTeam/WizardCoder-15B-V1.0",
    "provider": "WizardLM",
    "parameter_count": "15.5B",
    "parameters_raw": 15515334656,
    "min_ram_gb": 8.7,
    "recommended_ram_gb": 14.5,
    "min_vram_gb": 7.9,
    "quantization": "Q4_K_M",
    "context_length": 8192,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "bigcode/starcoder2-15b",
    "provider": "BigCode",
    "parameter_count": "15.7B",
    "parameters_raw": 15700000000,
    "min_ram_gb": 8.8,
    "recommended_ram_gb": 14.6,
    "min_vram_gb": 8.0,
    "quantization": "Q4_K_M",
    "context_length": 16384,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "starcoder2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct",
    "provider": "DeepSeek",
    "parameter_count": "16B",
    "parameters_raw": 15700000000,
    "min_ram_gb": 8.8,
    "recommended_ram_gb": 14.6,
    "min_vram_gb": 8.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v2",
    "is_moe": true,
    "num_experts": 64,
    "active_experts": 6,
    "active_parameters": 2400000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "inclusionAI/Ling-lite",
    "provider": "inclusionai",
    "parameter_count": "16.8B",
    "parameters_raw": 16801974272,
    "min_ram_gb": 9.4,
    "recommended_ram_gb": 15.6,
    "min_vram_gb": 8.6,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "bailing_moe",
    "hf_downloads": 92,
    "hf_likes": 78
  },
  {
    "name": "mistralai/Mistral-Small-24B-Instruct-2501",
    "provider": "Mistral AI",
    "parameter_count": "24B",
    "parameters_raw": 24000000000,
    "min_ram_gb": 13.4,
    "recommended_ram_gb": 22.4,
    "min_vram_gb": 12.3,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "mistral",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "google/gemma-2-27b-it",
    "provider": "Google",
    "parameter_count": "27.2B",
    "parameters_raw": 27227128320,
    "min_ram_gb": 15.2,
    "recommended_ram_gb": 25.4,
    "min_vram_gb": 13.9,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "gemma2",
    "hf_downloads": 394002,
    "hf_likes": 559
  },
  {
    "name": "Qwen/Qwen3-30B-A3B",
    "provider": "Alibaba",
    "parameter_count": "30B (3B active)",
    "parameters_raw": 30000000000,
    "min_ram_gb": 17.0,
    "recommended_ram_gb": 24.0,
    "min_vram_gb": 16.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 3300000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "30B (3B active)",
    "parameters_raw": 30000000000,
    "min_ram_gb": 17.0,
    "recommended_ram_gb": 24.0,
    "min_vram_gb": 16.0,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Code generation and understanding",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 3300000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "allenai/OLMo-2-0325-32B-Instruct",
    "provider": "allenai",
    "parameter_count": "32.2B",
    "parameters_raw": 32234279936,
    "min_ram_gb": 18.0,
    "recommended_ram_gb": 30.0,
    "min_vram_gb": 16.5,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "olmo2",
    "hf_downloads": 1395,
    "hf_likes": 148
  },
  {
    "name": "Qwen/Qwen2.5-32B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "32.5B",
    "parameters_raw": 32510000000,
    "min_ram_gb": 18.2,
    "recommended_ram_gb": 30.3,
    "min_vram_gb": 16.7,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "32.8B",
    "parameters_raw": 32763876352,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 723702,
    "hf_likes": 1997
  },
  {
    "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
    "provider": "DeepSeek",
    "parameter_count": "32.8B",
    "parameters_raw": 32763876352,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Advanced reasoning, chain-of-thought",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 969342,
    "hf_likes": 1518
  },
  {
    "name": "Qwen/Qwen3-32B",
    "provider": "Alibaba",
    "parameter_count": "32.8B",
    "parameters_raw": 32800000000,
    "min_ram_gb": 18.3,
    "recommended_ram_gb": 30.5,
    "min_vram_gb": 16.8,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "meta-llama/CodeLlama-34b-Instruct-hf",
    "provider": "Meta",
    "parameter_count": "33.7B",
    "parameters_raw": 33743970304,
    "min_ram_gb": 18.9,
    "recommended_ram_gb": 31.4,
    "min_vram_gb": 17.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Code generation and completion",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 1020,
    "hf_likes": 18
  },
  {
    "name": "01-ai/Yi-34B-Chat",
    "provider": "01.ai",
    "parameter_count": "34.4B",
    "parameters_raw": 34386780160,
    "min_ram_gb": 19.2,
    "recommended_ram_gb": 32.0,
    "min_vram_gb": 17.6,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Multilingual, Chinese/English chat",
    "pipeline_tag": "text-generation",
    "architecture": "yi",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "CohereForAI/c4ai-command-r-v01",
    "provider": "Cohere",
    "parameter_count": "35B",
    "parameters_raw": 35000000000,
    "min_ram_gb": 19.5,
    "recommended_ram_gb": 32.6,
    "min_vram_gb": 17.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "RAG, tool use, agents",
    "pipeline_tag": "text-generation",
    "architecture": "cohere",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "tiiuae/falcon-40b-instruct",
    "provider": "TII",
    "parameter_count": "40.0B",
    "parameters_raw": 40000000000,
    "min_ram_gb": 22.4,
    "recommended_ram_gb": 37.3,
    "min_vram_gb": 20.5,
    "quantization": "Q4_K_M",
    "context_length": 2048,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "provider": "Mistral AI",
    "parameter_count": "46.7B",
    "parameters_raw": 46702792704,
    "min_ram_gb": 26.1,
    "recommended_ram_gb": 43.5,
    "min_vram_gb": 23.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mixtral",
    "hf_downloads": 612617,
    "hf_likes": 4638,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 12900000000
  },
  {
    "name": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    "provider": "NousResearch",
    "parameter_count": "46.7B",
    "parameters_raw": 46702809088,
    "min_ram_gb": 26.1,
    "recommended_ram_gb": 43.5,
    "min_vram_gb": 23.9,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "mixtral",
    "hf_downloads": 8055,
    "hf_likes": 453,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 12900000000
  },
  {
    "name": "meta-llama/Llama-3.1-70B-Instruct",
    "provider": "Meta",
    "parameter_count": "70.6B",
    "parameters_raw": 70553706496,
    "min_ram_gb": 39.4,
    "recommended_ram_gb": 65.7,
    "min_vram_gb": 36.1,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 704871,
    "hf_likes": 892
  },
  {
    "name": "meta-llama/Llama-3.3-70B-Instruct",
    "provider": "Meta",
    "parameter_count": "70.6B",
    "parameters_raw": 70553706496,
    "min_ram_gb": 39.4,
    "recommended_ram_gb": 65.7,
    "min_vram_gb": 36.1,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "Qwen/Qwen2.5-72B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "72.7B",
    "parameters_raw": 72706203648,
    "min_ram_gb": 40.6,
    "recommended_ram_gb": 67.7,
    "min_vram_gb": 37.2,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "qwen2",
    "hf_downloads": 379554,
    "hf_likes": 910
  },
  {
    "name": "mistralai/Mixtral-8x22B-Instruct-v0.1",
    "provider": "Mistral AI",
    "parameter_count": "140.6B",
    "parameters_raw": 140630071296,
    "min_ram_gb": 78.6,
    "recommended_ram_gb": 131.0,
    "min_vram_gb": 72.0,
    "quantization": "Q4_K_M",
    "context_length": 65536,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "unknown",
    "architecture": "mixtral",
    "hf_downloads": 11797,
    "hf_likes": 746,
    "is_moe": true,
    "num_experts": 8,
    "active_experts": 2,
    "active_parameters": 39100000000
  },
  {
    "name": "rednote-hilab/dots.llm1.inst",
    "provider": "rednote-hilab",
    "parameter_count": "142.8B",
    "parameters_raw": 142774381696,
    "min_ram_gb": 79.8,
    "recommended_ram_gb": 133.0,
    "min_vram_gb": 73.1,
    "quantization": "Q4_K_M",
    "context_length": 32768,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "dots1",
    "hf_downloads": 4202,
    "hf_likes": 175
  },
  {
    "name": "bigscience/bloom",
    "provider": "bigscience",
    "parameter_count": "176.2B",
    "parameters_raw": 176247271424,
    "min_ram_gb": 98.5,
    "recommended_ram_gb": 164.1,
    "min_vram_gb": 90.3,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "bloom",
    "hf_downloads": 3181,
    "hf_likes": 4985
  },
  {
    "name": "tiiuae/falcon-180B-chat",
    "provider": "TII",
    "parameter_count": "179.5B",
    "parameters_raw": 179522565120,
    "min_ram_gb": 100.3,
    "recommended_ram_gb": 167.2,
    "min_vram_gb": 92.0,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "falcon",
    "hf_downloads": 75,
    "hf_likes": 545
  },
  {
    "name": "Qwen/Qwen3-235B-A22B",
    "provider": "Alibaba",
    "parameter_count": "235B (22B active)",
    "parameters_raw": 235000000000,
    "min_ram_gb": 131.3,
    "recommended_ram_gb": 218.9,
    "min_vram_gb": 120.5,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 22000000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "baidu/ERNIE-4.5-300B-A47B-Paddle",
    "provider": "baidu",
    "parameter_count": "300.5B",
    "parameters_raw": 300474051776,
    "min_ram_gb": 167.9,
    "recommended_ram_gb": 279.8,
    "min_vram_gb": 153.9,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "General purpose text generation",
    "pipeline_tag": "text-generation",
    "architecture": "ernie4_5_moe",
    "hf_downloads": 40,
    "hf_likes": 12
  },
  {
    "name": "meta-llama/Llama-3.1-405B-Instruct",
    "provider": "Meta",
    "parameter_count": "405.9B",
    "parameters_raw": 405853388800,
    "min_ram_gb": 226.8,
    "recommended_ram_gb": 378.0,
    "min_vram_gb": 207.9,
    "quantization": "Q4_K_M",
    "context_length": 4096,
    "use_case": "Instruction following, chat",
    "pipeline_tag": "text-generation",
    "architecture": "llama",
    "hf_downloads": 150033,
    "hf_likes": 592
  },
  {
    "name": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "provider": "Alibaba",
    "parameter_count": "480B (35B active)",
    "parameters_raw": 480000000000,
    "min_ram_gb": 268.2,
    "recommended_ram_gb": 447.0,
    "min_vram_gb": 246.2,
    "quantization": "Q4_K_M",
    "context_length": 262144,
    "use_case": "Code generation and understanding",
    "pipeline_tag": "text-generation",
    "architecture": "qwen3_moe",
    "is_moe": true,
    "num_experts": 128,
    "active_experts": 8,
    "active_parameters": 35000000000,
    "hf_downloads": 0,
    "hf_likes": 0
  },
  {
    "name": "deepseek-ai/DeepSeek-V3",
    "provider": "DeepSeek",
    "parameter_count": "685B",
    "parameters_raw": 685000000000,
    "min_ram_gb": 382.8,
    "recommended_ram_gb": 638.0,
    "min_vram_gb": 351.3,
    "quantization": "Q4_K_M",
    "context_length": 131072,
    "use_case": "State-of-the-art, MoE architecture",
    "pipeline_tag": "text-generation",
    "architecture": "deepseek_v3",
    "is_moe": true,
    "num_experts": 256,
    "active_experts": 8,
    "active_parameters": 37000000000,
    "hf_downloads": 0,
    "hf_likes": 0
  }
]